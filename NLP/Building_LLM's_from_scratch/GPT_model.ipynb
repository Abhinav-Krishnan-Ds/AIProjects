{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 128,\n",
    "    \"emb_dim\" : 708,\n",
    "    \"n_heads\" : 12,\n",
    "    \"n_layers\" : 11,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of charecters in the text:  1001524\n",
      "\n",
      "First 100 charecters of raw_text:\n",
      " The Project Gutenberg eBook of A Moslem seeker after God\n",
      "    \n",
      "This ebook is for the use of anyone a\n",
      "\n",
      "Last 100 charecters of text_data: \n",
      "  produce our new eBooks, and how to\n",
      "subscribe to our email newsletter to hear about new eBooks.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/abhinav/Documents/Work/2 Hobby_projects/Datasets/NLP_LLM/antxt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "print(\"Total number of charecters in the text: \", len(text_data))\n",
    "print(\"\\nFirst 100 charecters of raw_text:\\n\", text_data[:99])\n",
    "print(\"\\nLast 100 charecters of text_data: \\n\", text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = 1e-05\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        variance = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x-mean) / (torch.sqrt(variance + self.eps))\n",
    "\n",
    "        return self.scale * norm_x + self.shift\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return  0.5 * x * ( 1 + torch.tanh( torch.sqrt(  torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3)  ) ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.ff = FeedForward(cfg=cfg)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input to transformer block:  torch.Size([2, 4, 708])\n",
      "Shape of output of transformer block:  torch.Size([2, 4, 708])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "sample_input = torch.rand(2, 4, GPT_CONFIG_124M[\"emb_dim\"])\n",
    "tb = TransformerBlock(GPT_CONFIG_124M)\n",
    "\n",
    "print(\"Shape of input to transformer block: \", sample_input.shape)\n",
    "output = tb(sample_input)\n",
    "print(\"Shape of output of transformer block: \", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[ TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"]) ]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.token_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 708)\n",
       "  (pos_emb): Embedding(128, 708)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=708, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probab = torch.softmax(logits, dim=-1)\n",
    "        id_next = torch.argmax(probab, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, id_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6109,  3626,  6100, 22359, 24083,  2841, 24725, 16656, 48350,  1443,\n",
      "         28090, 45822, 19624]])\n",
      "Generated text:  Every effort moves tumor gratitudeees saturated Ship maximizingbs Updates Cortana recruitment\n"
     ]
    }
   ],
   "source": [
    "# This is a code that generates next max_new_tokens number of new tokens to extend the initial text\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    tokens = tokenizer.encode(text, allowed_special={\"<|endoftoken|>\"})\n",
    "    tokens = torch.tensor(tokens).unsqueeze(0)\n",
    "    return tokens\n",
    "\n",
    "def token_ids_to_text(idx, tokenizer):\n",
    "    text = idx.squeeze(0)\n",
    "    return tokenizer.decode(text.tolist())\n",
    "\n",
    "start_context = \"Every effort moves\"\n",
    "gtt = generate_text_simple(model=model, idx=text_to_token_ids(start_context, tokenizer=tokenizer), max_new_tokens=10, context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(gtt)\n",
    "print(\"Generated text: \", token_ids_to_text(gtt, tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities shape:  torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"Probabilities shape: \", probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "tensor([[[22960],\n",
      "         [13655],\n",
      "         [ 7763]],\n",
      "\n",
      "        [[32033],\n",
      "         [16648],\n",
      "         [39864]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Output:\")\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \n",
      " resemblesgt contained\n",
      "Required text:\n",
      " effort moves you\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated text: \")\n",
    "print(token_ids_to_text(token_ids[0].flatten(), tokenizer=tokenizer))\n",
    "print(\"Required text:\")\n",
    "print(token_ids_to_text(targets[0], tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of probability output tensor:  torch.Size([2, 3, 50257])\n",
      "Shape of target:  torch.Size([2, 3])\n",
      "Shape of requre:  [tensor([1.5757e-05, 1.5602e-05, 5.1567e-06]), tensor([1.0869e-05, 1.4544e-05, 9.5428e-06])]\n",
      "tensor([1.5757e-05, 1.5602e-05, 5.1567e-06, 1.0869e-05, 1.4544e-05, 9.5428e-06])\n",
      "tensor([-11.0582, -11.0681, -12.1752, -11.4296, -11.1383, -11.5597])\n",
      "tensor(-11.4049)\n",
      "Loss:  tensor(11.4049)\n"
     ]
    }
   ],
   "source": [
    "# Finding loss from logits (output of gpt model) and target\n",
    "\n",
    "print(\"Shape of probability output tensor: \", probas.shape)\n",
    "\n",
    "print(\"Shape of target: \", targets.shape)\n",
    "\n",
    "target_probabilities = []\n",
    "for b in range(probas.shape[0]):\n",
    "    batc = b\n",
    "    target_probabilities.append(probas[batc, torch.arange(probas.shape[1]), targets[batc]])\n",
    "print(\"Shape of requre: \", target_probabilities)\n",
    "target_probabilities = torch.cat(target_probabilities, dim=0)\n",
    "print(target_probabilities)\n",
    "\n",
    "target_probabilities = torch.log(target_probabilities)\n",
    "print(target_probabilities)\n",
    "\n",
    "loss = torch.mean(target_probabilities)\n",
    "print(loss)\n",
    "loss = (loss * -1)\n",
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of logits and target after flatten:\n",
      "torch.Size([6, 50257])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flaten = logits.flatten(0, 1)\n",
    "target_flaten = targets.flatten(0, 1)\n",
    "print(\"shape of logits and target after flatten:\")\n",
    "print(logits_flaten.shape)\n",
    "print(target_flaten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.4049)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flaten, target_flaten)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(89757.9531)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(123)\n",
    "\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# print(\"Shape of input: \", batch.shape)\n",
    "\n",
    "# output = model(batch)\n",
    "\n",
    "# print(\"Shape of output: \", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_parameters = sum(p.numel() for p in model.parameters())\n",
    "# print(\"Total number of parameters in GPT model: \", Total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Token embedding layer shape: \", model.token_emb.weight.shape)\n",
    "# print(\"Output layer shape: \", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_parameters_gpt2 = Total_parameters - sum(p.numel() for p in model.out_head.parameters())\n",
    "# print(\"Total parameters using weight tying: \", Total_parameters_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To calculate total space requirement\n",
    "\n",
    "# total_param_bytes = Total_parameters * 4\n",
    "# total_param_mb = total_param_bytes / (1024*1024)\n",
    "# print(f\"Total memory requirement: {total_param_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "#     for _ in range(max_new_tokens):\n",
    "#         idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "#         # Get the predictions\n",
    "#         with torch.no_grad():\n",
    "#             logits = model(idx_cond)\n",
    "\n",
    "#         logits = logits[:, -1, :]\n",
    "#         probab = torch.softmax(logits, dim=-1)\n",
    "#         id_next = torch.argmax(probab, dim=-1, keepdim=True)\n",
    "#         idx = torch.cat((idx, id_next), dim=1)\n",
    "#     return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_context = \"Hello, I am\"\n",
    "# encoded = tokenizer.encode(start_context)\n",
    "# print(\"encoded:\", encoded)\n",
    "# encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "# print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "# out = generate_text_simple(\n",
    "#     model=model,\n",
    "#     idx=encoded_tensor,\n",
    "#     max_new_tokens=6,\n",
    "#     context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "# )\n",
    "# print(\"Output:\", out)\n",
    "# print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.decode(out.squeeze(0).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total charecters in text data:  1001524\n",
      "Total tokens after tokenization:  320834\n"
     ]
    }
   ],
   "source": [
    "total_charecters = len(text_data)\n",
    "tokens = tokenizer.encode(text=text_data)\n",
    "total_tokens = len(tokens)\n",
    "\n",
    "print(\"Total charecters in text data: \", total_charecters)\n",
    "print(\"Total tokens after tokenization: \", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1:\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.output_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0, len(token_ids)-max_length, stride):\n",
    "            input_chunk = token_ids[i : i+max_length]\n",
    "            ouput_chunk = token_ids[i+1 : i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.output_ids.append(torch.tensor(ouput_chunk))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.output_ids[idx]\n",
    "    \n",
    "def create_dataloader_v1(txt, max_length, stride, batch_size, shuffle, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length=max_length, stride=stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=drop_last,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    txt=train_data,\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    txt=val_data,\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loader:\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "\n",
      "Valid loader\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([3, 128]) torch.Size([3, 128])\n",
      "torch.Size([1, 128]) torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValid loader\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tokens:  292608\n",
      "Validation tokens:  27776\n",
      "Total number of tokens:  320384\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "valid_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    valid_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Train tokens: \", train_tokens)\n",
    "print(\"Validation tokens: \", valid_tokens)\n",
    "print(\"Total number of tokens: \", train_tokens + valid_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[ TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"]) ]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.token_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 708)\n",
       "  (pos_emb): Embedding(128, 708)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_key): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (W_value): Linear(in_features=708, out_features=708, bias=False)\n",
       "        (out_proj): Linear(in_features=708, out_features=708, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=708, out_features=2832, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=2832, out_features=708, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=708, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(dataloader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(dataloader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(dataloader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(dataloader):\n",
    "        loss = calc_loss_batch(input_batch=input_batch, target_batch=target_batch, model=model, device=device)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  11.001613427960654\n",
      "Validation loss:  10.989713890911782\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device=device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "\n",
    "print(\"Training loss: \", train_loss)\n",
    "print(\"Validation loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device=device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, encoded, 50, context_size)\n",
    "    decoded = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, accumulation_steps, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch : \", epoch+1)\n",
    "        print(\"\\n\")\n",
    "        model.train()\n",
    "        for i, (input_batch, target_batch) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch=input_batch, target_batch=target_batch, model=model, device=device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Global step: {global_step}\"\n",
    "                      f\"Training loss: {train_loss:.3f}, Validation loss: {val_loss:.3f}\")\n",
    "                \n",
    "        generate_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre training loop\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprin\u001b[49m(sdfs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prin' is not defined"
     ]
    }
   ],
   "source": [
    "prin(sdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61280/48580753.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"/home/abhinav/Documents/Work/2 Hobby_projects/Models/LLM_gpt2model/model_and_optimizer.pth\")\n"
     ]
    }
   ],
   "source": [
    "# Later we can load as\n",
    "checkpoint = torch.load(\"/home/abhinav/Documents/Work/2 Hobby_projects/Models/LLM_gpt2model/model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1\n",
      "\n",
      "\n",
      "Global step: 0Training loss: 1532.242, Validation loss: 149.636\n",
      "Global step: 5Training loss: 1245.525, Validation loss: 121.686\n",
      "Global step: 10Training loss: 1183.082, Validation loss: 120.078\n",
      "Global step: 15Training loss: 1185.404, Validation loss: 122.033\n",
      "Global step: 20Training loss: 1138.787, Validation loss: 114.750\n",
      "Global step: 25Training loss: 1117.609, Validation loss: 110.567\n",
      "Global step: 30Training loss: 1119.752, Validation loss: 113.837\n",
      "Global step: 35Training loss: 1111.503, Validation loss: 113.798\n",
      "Global step: 40Training loss: 1299.752, Validation loss: 112.371\n",
      "Global step: 45Training loss: 1110.052, Validation loss: 108.993\n",
      "Global step: 50Training loss: 1097.357, Validation loss: 107.217\n",
      "Global step: 55Training loss: 1076.241, Validation loss: 106.247\n",
      "Global step: 60Training loss: 1062.995, Validation loss: 105.328\n",
      "Global step: 65Training loss: 1050.639, Validation loss: 105.851\n",
      "Global step: 70Training loss: 1047.116, Validation loss: 105.518\n",
      "Global step: 75Training loss: 1058.658, Validation loss: 105.190\n",
      "Global step: 80Training loss: 1053.457, Validation loss: 106.168\n",
      "Global step: 85Training loss: 1035.120, Validation loss: 102.931\n",
      "Global step: 90Training loss: 1024.994, Validation loss: 102.808\n",
      "Global step: 95Training loss: 1022.646, Validation loss: 103.525\n",
      "Global step: 100Training loss: 1023.744, Validation loss: 104.045\n",
      "Global step: 105Training loss: 1016.484, Validation loss: 102.389\n",
      "Global step: 110Training loss: 1012.087, Validation loss: 101.486\n",
      "Global step: 115Training loss: 1009.057, Validation loss: 100.965\n",
      "Global step: 120Training loss: 1009.151, Validation loss: 101.086\n",
      "Global step: 125Training loss: 1008.838, Validation loss: 101.938\n",
      "Global step: 130Training loss: 1007.925, Validation loss: 101.098\n",
      "Global step: 135Training loss: 1005.869, Validation loss: 100.518\n",
      "Global step: 140Training loss: 996.160, Validation loss: 99.285\n",
      "Global step: 145Training loss: 993.380, Validation loss: 98.618\n",
      "Global step: 150Training loss: 988.417, Validation loss: 98.979\n",
      "Global step: 155Training loss: 996.799, Validation loss: 101.694\n",
      "Global step: 160Training loss: 989.374, Validation loss: 99.924\n",
      "Global step: 165Training loss: 981.776, Validation loss: 98.813\n",
      "Global step: 170Training loss: 978.533, Validation loss: 97.990\n",
      "Global step: 175Training loss: 977.178, Validation loss: 97.443\n",
      "Global step: 180Training loss: 972.326, Validation loss: 97.265\n",
      "Global step: 185Training loss: 971.004, Validation loss: 97.880\n",
      "Global step: 190Training loss: 966.130, Validation loss: 96.274\n",
      "Global step: 195Training loss: 965.323, Validation loss: 95.817\n",
      "Global step: 200Training loss: 959.812, Validation loss: 95.407\n",
      "Global step: 205Training loss: 961.966, Validation loss: 96.399\n",
      "Global step: 210Training loss: 959.309, Validation loss: 96.202\n",
      "Global step: 215Training loss: 961.375, Validation loss: 96.159\n",
      "Global step: 220Training loss: 958.973, Validation loss: 95.768\n",
      "Global step: 225Training loss: 955.556, Validation loss: 94.872\n",
      "Global step: 230Training loss: 953.685, Validation loss: 95.430\n",
      "Global step: 235Training loss: 955.408, Validation loss: 96.408\n",
      "Global step: 240Training loss: 948.416, Validation loss: 95.070\n",
      "Global step: 245Training loss: 945.673, Validation loss: 94.373\n",
      "Global step: 250Training loss: 943.371, Validation loss: 94.178\n",
      "Global step: 255Training loss: 940.846, Validation loss: 93.188\n",
      "Global step: 260Training loss: 940.615, Validation loss: 93.063\n",
      "Global step: 265Training loss: 944.651, Validation loss: 94.686\n",
      "Global step: 270Training loss: 944.586, Validation loss: 95.143\n",
      "Global step: 275Training loss: 937.374, Validation loss: 93.268\n",
      "Global step: 280Training loss: 932.802, Validation loss: 93.110\n",
      "Global step: 285Training loss: 929.882, Validation loss: 93.202\n",
      "Global step: 290Training loss: 927.992, Validation loss: 93.483\n",
      "Global step: 295Training loss: 927.928, Validation loss: 94.091\n",
      "Global step: 300Training loss: 926.820, Validation loss: 93.978\n",
      "Global step: 305Training loss: 923.350, Validation loss: 93.264\n",
      "Global step: 310Training loss: 923.232, Validation loss: 92.674\n",
      "Global step: 315Training loss: 920.570, Validation loss: 91.867\n",
      "Global step: 320Training loss: 915.510, Validation loss: 91.195\n",
      "Global step: 325Training loss: 916.876, Validation loss: 92.620\n",
      "Global step: 330Training loss: 925.327, Validation loss: 91.858\n",
      "Global step: 335Training loss: 921.290, Validation loss: 92.332\n",
      "Global step: 340Training loss: 921.566, Validation loss: 92.280\n",
      "Global step: 345Training loss: 917.219, Validation loss: 92.314\n",
      "Global step: 350Training loss: 911.294, Validation loss: 91.985\n",
      "Global step: 355Training loss: 913.032, Validation loss: 92.164\n",
      "Global step: 360Training loss: 907.880, Validation loss: 91.951\n",
      "Global step: 365Training loss: 905.960, Validation loss: 90.833\n",
      "Global step: 370Training loss: 903.661, Validation loss: 90.779\n",
      "Global step: 375Training loss: 901.166, Validation loss: 90.753\n",
      "Global step: 380Training loss: 901.598, Validation loss: 91.295\n",
      "Global step: 385Training loss: 898.623, Validation loss: 90.794\n",
      "Global step: 390Training loss: 899.060, Validation loss: 90.702\n",
      "Global step: 395Training loss: 895.771, Validation loss: 90.613\n",
      "Global step: 400Training loss: 896.009, Validation loss: 91.080\n",
      "Global step: 405Training loss: 893.712, Validation loss: 91.015\n",
      "Global step: 410Training loss: 894.322, Validation loss: 91.554\n",
      "Global step: 415Training loss: 891.489, Validation loss: 90.589\n",
      "Global step: 420Training loss: 887.758, Validation loss: 90.605\n",
      "Global step: 425Training loss: 886.057, Validation loss: 90.754\n",
      "Global step: 430Training loss: 887.756, Validation loss: 90.957\n",
      "Global step: 435Training loss: 882.889, Validation loss: 90.536\n",
      "Global step: 440Training loss: 881.480, Validation loss: 90.241\n",
      "Global step: 445Training loss: 884.376, Validation loss: 90.314\n",
      "Global step: 450Training loss: 883.869, Validation loss: 90.289\n",
      "Global step: 455Training loss: 888.108, Validation loss: 90.635\n",
      "Global step: 460Training loss: 878.787, Validation loss: 89.602\n",
      "Global step: 465Training loss: 880.880, Validation loss: 89.226\n",
      "Global step: 470Training loss: 885.186, Validation loss: 90.819\n",
      "Global step: 475Training loss: 880.370, Validation loss: 89.230\n",
      "Global step: 480Training loss: 884.491, Validation loss: 88.995\n",
      "Global step: 485Training loss: 876.457, Validation loss: 88.981\n",
      "Global step: 490Training loss: 875.813, Validation loss: 90.004\n",
      "Global step: 495Training loss: 874.818, Validation loss: 89.855\n",
      "Global step: 500Training loss: 871.894, Validation loss: 88.542\n",
      "Global step: 505Training loss: 869.986, Validation loss: 88.514\n",
      "Global step: 510Training loss: 873.528, Validation loss: 90.026\n",
      "Global step: 515Training loss: 867.320, Validation loss: 88.675\n",
      "Global step: 520Training loss: 864.497, Validation loss: 88.398\n",
      "Global step: 525Training loss: 866.378, Validation loss: 88.626\n",
      "Global step: 530Training loss: 862.994, Validation loss: 88.388\n",
      "Global step: 535Training loss: 863.610, Validation loss: 88.695\n",
      "Global step: 540Training loss: 861.042, Validation loss: 87.793\n",
      "Global step: 545Training loss: 866.719, Validation loss: 87.702\n",
      "Global step: 550Training loss: 864.556, Validation loss: 87.482\n",
      "Global step: 555Training loss: 860.137, Validation loss: 87.469\n",
      "Global step: 560Training loss: 859.473, Validation loss: 88.223\n",
      "Global step: 565Training loss: 854.859, Validation loss: 87.568\n",
      "Global step: 570Training loss: 854.946, Validation loss: 87.506\n",
      "Global step: 575Training loss: 855.231, Validation loss: 87.525\n",
      "Global step: 580Training loss: 850.949, Validation loss: 87.232\n",
      "Global step: 585Training loss: 850.190, Validation loss: 86.607\n",
      "Global step: 590Training loss: 848.536, Validation loss: 86.730\n",
      "Global step: 595Training loss: 849.415, Validation loss: 87.125\n",
      "Global step: 600Training loss: 847.403, Validation loss: 86.934\n",
      "Global step: 605Training loss: 847.289, Validation loss: 87.089\n",
      "Global step: 610Training loss: 848.001, Validation loss: 86.769\n",
      "Global step: 615Training loss: 850.367, Validation loss: 87.009\n",
      "Global step: 620Training loss: 849.892, Validation loss: 87.345\n",
      "Global step: 625Training loss: 844.861, Validation loss: 86.910\n",
      "Global step: 630Training loss: 845.344, Validation loss: 86.681\n",
      "Global step: 635Training loss: 844.090, Validation loss: 87.031\n",
      "Global step: 640Training loss: 842.535, Validation loss: 86.782\n",
      "Global step: 645Training loss: 843.581, Validation loss: 86.234\n",
      "Global step: 650Training loss: 846.376, Validation loss: 86.522\n",
      "Global step: 655Training loss: 842.578, Validation loss: 86.367\n",
      "Global step: 660Training loss: 839.330, Validation loss: 86.508\n",
      "Global step: 665Training loss: 839.341, Validation loss: 86.077\n",
      "Global step: 670Training loss: 842.111, Validation loss: 86.364\n",
      "Global step: 675Training loss: 841.205, Validation loss: 86.516\n",
      "Global step: 680Training loss: 840.030, Validation loss: 86.564\n",
      "Global step: 685Training loss: 838.265, Validation loss: 86.401\n",
      "Global step: 690Training loss: 840.660, Validation loss: 86.844\n",
      "Global step: 695Training loss: 836.610, Validation loss: 86.601\n",
      "Global step: 700Training loss: 836.654, Validation loss: 86.599\n",
      "Global step: 705Training loss: 833.831, Validation loss: 86.103\n",
      "Global step: 710Training loss: 833.140, Validation loss: 86.056\n",
      "Global step: 715Training loss: 835.724, Validation loss: 86.839\n",
      "Global step: 720Training loss: 835.072, Validation loss: 86.605\n",
      "Global step: 725Training loss: 830.301, Validation loss: 85.942\n",
      "Global step: 730Training loss: 828.983, Validation loss: 85.634\n",
      "Global step: 735Training loss: 829.788, Validation loss: 86.248\n",
      "Global step: 740Training loss: 832.387, Validation loss: 86.870\n",
      "Global step: 745Training loss: 827.408, Validation loss: 85.579\n",
      "Global step: 750Training loss: 828.036, Validation loss: 85.259\n",
      "Global step: 755Training loss: 824.494, Validation loss: 85.174\n",
      "Global step: 760Training loss: 824.134, Validation loss: 85.467\n",
      "Every step moves you.                                                 \n",
      "Total time taken for training the LLM: 102.41 minutes\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device=device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model, \n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    accumulation_steps=1,\n",
    "    start_context=\"Every step moves you\",\n",
    "    tokenizer=tokenizer)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time taken for training the LLM: {(end_time - start_time)/60:.2f} minutes\")\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\" : model.state_dict(),\n",
    "    \"optimizer_state_dict\" : optimizer.state_dict()\n",
    "    },\n",
    "    \"/home/abhinav/Documents/Work/2 Hobby_projects/Models/LLM_gpt2model/model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later we can load as\n",
    "# checkpoint = torch.load(\"/home/abhinav/Documents/Work/2 Hobby_projects/Models/LLM_gpt2model/model_and_optimizer.pth\")\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "# optimizer.load_state_dict(checkpoint[\"parameter_state_dict\"])\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate(model, idx, max_new_tokens, context_size, temperature=0.0, topk=None, eos_id=None):\n",
    "#     for _ in range(max_new_tokens):\n",
    "#         idx_cond = idx[:, -context_size:]\n",
    "#         # idx_cond = idx_cond.to(device=device)\n",
    "#         with torch.no_grad():\n",
    "#             logits = model(idx_cond)\n",
    "#         logits = logits[:, -1, :]\n",
    "\n",
    "#         if topk is not None:\n",
    "#             top_logits, _ = torch.topk(logits, topk)\n",
    "#             min_val = top_logits[:, -1]\n",
    "#             logits = torch.where(condition= logits < min_val, input=torch.tensor(float(\"-inf\")).to(logits.device), other=logits)\n",
    "        \n",
    "#         if temperature > 0:\n",
    "#             logits = logits / temperature\n",
    "#             probas = torch.softmax(logits, dim=0)\n",
    "#             id_next = torch.multinomial(probas, num_samples=1)\n",
    "#         else:\n",
    "#             id_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "#         if id_next == eos_id:\n",
    "#             break\n",
    "        \n",
    "#         idx = torch.cat((idx, id_next), dim=1)\n",
    "    \n",
    "#     return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m generate(\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      5\u001b[0m     idx\u001b[38;5;241m=\u001b[39mtext_to_token_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvery effort moves you\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.4\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, token_ids_to_text(token_ids, tokenizer))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/random.py:46\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/random.py:129\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    126\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    127\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 129\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:249\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 249\u001b[0m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/random.py:127\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[1;32m    126\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
