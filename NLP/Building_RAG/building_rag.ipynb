{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"T94Gyskpuxe33SoWIJUTWzgi6P17fK4YS5OhGSl5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.\n",
    "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.\n",
    "Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.\n",
    "\n",
    "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007.\n",
    "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar.\n",
    "Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm.\n",
    "Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles.\n",
    "Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects.\n",
    "\n",
    "Interstellar premiered on October 26, 2014, in Los Angeles.\n",
    "In the United States, it was first released on film stock, expanding to venues using digital projectors.\n",
    "The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014.\n",
    "It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight.\n",
    "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics. Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time.\n",
    "Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "texts = text.split('.')\n",
    "\n",
    "texts = [t.strip(' \\n') for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 4096)\n"
     ]
    }
   ],
   "source": [
    "respones = co.embed(\n",
    "    texts=texts,\n",
    "    input_type=\"search_document\"\n",
    ").embeddings\n",
    "\n",
    "embeds = np.array(respones)\n",
    "print(embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = embeds.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(np.float32(embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, num_of_results=3):\n",
    "    query_embed = co.embed(\n",
    "        texts=[query],\n",
    "        input_type=\"search_query\"\n",
    "    ).embeddings[0]\n",
    "\n",
    "    distances, similar_item_ids = index.search(np.float32([query_embed]), num_of_results)\n",
    "\n",
    "    text_np = np.array(texts)\n",
    "    results = pd.DataFrame(data={\n",
    "        \"texts\":text_np[similar_item_ids[0]],\n",
    "        \"distances\":distances[0]\n",
    "    })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               texts     distances\n",
      "0  It has also received praise from many astronom...  10757.379883\n"
     ]
    }
   ],
   "source": [
    "query = \"how precise was the science\"\n",
    "\n",
    "result = search(query, 1)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 91048.57it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = []\n",
    "\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search(query, top_k=3, num_candidates=15):\n",
    "    print(\"Input question:\", query)\n",
    "\n",
    "    ##### BM25 search (lexical search) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x[\"score\"], reverse=True)\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: how precise was the science\n",
      "\t1.789\tInterstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan\n",
      "\t1.373\tCaltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar\n",
      "\t0.000\tIt stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine\n"
     ]
    }
   ],
   "source": [
    "keyword_search(query = \"how precise was the science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RerankResponseResultsItem(document=RerankResponseResultsItemDocument(text='It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics'), index=12, relevance_score=0.16981852),\n",
       " RerankResponseResultsItem(document=RerankResponseResultsItemDocument(text='The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014'), index=10, relevance_score=0.07004896),\n",
       " RerankResponseResultsItem(document=RerankResponseResultsItemDocument(text='Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar'), index=4, relevance_score=0.0043994132)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how precise was the science\"\n",
    "results = co.rerank(query=query, documents=texts, top_n=3, return_documents=True)\n",
    "results.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.16981852 It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics\n",
      "1 0.07004896 The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014\n",
      "2 0.0043994132 Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar\n"
     ]
    }
   ],
   "source": [
    "for idx, result in enumerate(results.results):\n",
    "    print(idx, result.relevance_score , result.document.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_and_reranking_search(query, top_k=3, num_candidates=10):\n",
    "    print(\"Input question:\", query)\n",
    "\n",
    "    ##### BM25 search (lexical search) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "\n",
    "    #Add re-ranking\n",
    "    docs = [texts[hit['corpus_id']] for hit in bm25_hits]\n",
    "\n",
    "    print(f\"\\nTop-3 hits by rank-API ({len(bm25_hits)} BM25 hits re-ranked)\")\n",
    "    results = co.rerank(query=query, documents=docs, top_n=top_k, return_documents=True)\n",
    "    for hit in results.results:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit.relevance_score, hit.document.text.replace(\"\\n\", \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: how precise was the science\n",
      "Top-3 lexical search (BM25) hits\n",
      "\t1.789\tInterstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan\n",
      "\t1.373\tCaltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar\n",
      "\t0.000\tInterstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects\n",
      "\n",
      "Top-3 hits by rank-API (10 BM25 hits re-ranked)\n",
      "\t0.004\tCaltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar\n",
      "\t0.004\tSet in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind\n",
      "\t0.003\tBrothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007\n"
     ]
    }
   ],
   "source": [
    "keyword_and_reranking_search(query = \"how precise was the science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The film grossed over $677 million worldwide, and $773 million with subsequent re-releases.\n"
     ]
    }
   ],
   "source": [
    "# This is a RAG which uses LLM api from Cohere\n",
    "\n",
    "query = \"income generated\"\n",
    "\n",
    "# 1- Retrieval\n",
    "# We'll use embedding search. But ideally we'd do hybrid\n",
    "\n",
    "### Dense retrieval\n",
    "results = search(query)\n",
    "\n",
    "\n",
    "### Generation\n",
    "# 2- Grounded Generation\n",
    "docs_dict = [{'text': text} for text in results['texts']]\n",
    "response = co.chat(\n",
    "    message = query,\n",
    "    documents=docs_dict\n",
    ")\n",
    "\n",
    "### Retrieval + Generation => Grounded LLM (RAG)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To download any model from huggingface\n",
    "# # This is a direct way of downloading models, you need to search about how to show \n",
    "# # that we have access to certain models\n",
    "\n",
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "# snapshot_download(\n",
    "#     repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "#     local_dir=\"/home/abhinav/Desktop/AIProjects/NLP/Building_RAG/\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The below code is to download using transformers library\n",
    "\n",
    "# import torch\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# model_name = \"\"\n",
    "\n",
    "# # The below code is to download a model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer.save_pretrained(f\"cache/tokenizer/{model_name}\")\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# model.save_pretrained(f\"cache/model/{model_name}\")\n",
    "\n",
    "\n",
    "# # The below code is to load the model from local directory\n",
    "# tokenizer = AutoTokenizer.from_pretrained(f\"cache/tokenizer/{model_name}\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(f\"cache/model/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We download all the models from huggingface to the cache directory\n",
    "# # ./cache/huggingface/hub\n",
    "# # GO to this directory, choose the model you want to download, go to snapshots, and you will find a folder\n",
    "# # This folder contains the config.json file\n",
    "# # Get the path to this folder and paste it in model_name_or_path\n",
    "\n",
    "# model_name_or_path= \"/home/abhinav/.cache/huggingface/hub/models--thenlper--gte-small/snapshots/17e1f347d17fe144873b1201da91788898c639cd\"\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To use the downloaded model using llama-cpp\n",
    "\n",
    "# from langchain import LlamaCpp\n",
    "\n",
    "# # Make sure the model path is correct for your system!\n",
    "# llm = LlamaCpp(\n",
    "#     model_path=\"Phi-3-mini-4k-instruct-fp16.gguf\",\n",
    "#     n_gpu_layers=-1,\n",
    "#     max_tokens=500,\n",
    "#     n_ctx=2048,\n",
    "#     seed=42,\n",
    "#     verbose=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use a model downloaded from ollama\n",
    "\n",
    "# from langchain_community.llms import Ollama\n",
    "\n",
    "# llm = Ollama(model=\"gemma:2b\")\n",
    "# llm.invoke(\"tell me about partial functions in python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To use a model using ollama library\n",
    "\n",
    "# import ollama\n",
    "\n",
    "# response = ollama.generate(model='gemma:2b',\n",
    "# prompt='what is a qubit?')\n",
    "# print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11391/4255497338.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n",
      "2025-01-23 08:22:47.533830: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-23 08:22:47.695335: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-23 08:22:47.695382: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-23 08:22:47.713684: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-23 08:22:47.752041: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-23 08:22:48.579223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# This is to download a model from huggingface embeddings\n",
    "# This code uses the model if it's downloaded in the cache directory, else, it downloads from the web\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Embedding Model for converting text to numerical representations\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='thenlper/gte-small'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a detailed explanation of partial functions in Python:\\n\\n**Partial Functions**\\n\\nPartial functions are functions that take a subset of the arguments of a full function and return a single value. They are commonly used when you have a function that operates on a set of data and you want to apply it to only a subset of that data.\\n\\n**Syntax**\\n\\nA partial function is defined using the same syntax as a full function, except that you specify the arguments that you want to pass to the function. For example, the following code defines a partial function called `partial_sum` that takes two arguments, `a` and `b`, and returns the sum of those two arguments:\\n\\n```python\\npartial_sum = lambda a, b: a + b\\n```\\n\\n**Examples**\\n\\nHere are a few examples of partial functions in Python:\\n\\n* `partial_sum(2, 3)` returns 5\\n* `partial_sum(4, 5, 6)` returns 15\\n* `partial_sum(a, b)` returns the same value as `partial_sum(a, b)`\\n\\n**Uses**\\n\\nPartial functions can be used for a variety of purposes, including:\\n\\n* Filtering a list of data based on a subset of the data\\n* Computing the sum of a subset of a list of data\\n* Performing a calculation on a subset of a data set\\n* Creating a new function that applies a given function to a subset of the input data\\n\\n**Advantages**\\n\\n* Partial functions can be used to perform calculations on a subset of data without having to iterate through the entire dataset.\\n* They can be used to create more complex functions by combining multiple partial functions.\\n* They can be used to improve the performance of code by reducing the amount of data that needs to be processed.\\n\\n**Disadvantages**\\n\\n* Partial functions can be difficult to debug, as the behavior of a partial function can depend on the order of the arguments.\\n* They can be used to introduce a level of abstraction that can make it more difficult to understand and maintain code.\\n\\n**Conclusion**\\n\\nPartial functions are a powerful tool that can be used to perform calculations on a subset of data. They can be used for a variety of purposes, such as filtering a list of data based on a subset of the data, computing the sum of a subset of a list of data, and creating a new function that applies a given function to a subset of the input data.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use a model downloaded from ollama\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"gemma:2b\")\n",
    "llm.invoke(\"tell me about partial functions in python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a local vector store database\n",
    "\n",
    "db = FAISS.from_texts(texts, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<|user|>\n",
    "Relevant information:\n",
    "{context}\n",
    "\n",
    "Provide a concise answer the following question using the relevant information provided above:\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RAG Pipeline\n",
    "## RetrievalQA:\n",
    "# A pre-built class in langchain designed to handle Retrieval-Augmented Generation (RAG).\n",
    "# It combines a retrieval mechanism (fetching relevant data) with a language model for answering questions.\n",
    "\n",
    "\n",
    "# How to retrieve custom number of documents or put similarity score thresholds?\n",
    "# retriever = db.as_retriever(search_kwargs={\"k\": 5})  # Retrieve the top 5 documents\n",
    "# retriever = dv.as_retriever( search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5})\n",
    "\n",
    "\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=db.as_retriever(),\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt\n",
    "    },\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Income generated',\n",
       " 'result': 'The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases).'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.invoke('Income generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
