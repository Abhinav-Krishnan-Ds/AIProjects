{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from data: tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Initializing a tensor\n",
    "\n",
    "# Directly from data\n",
    "\n",
    "data = [[1, 2, 3, 4], [5, 6, 7, 8]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(\"Tensor from data:\", x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from np array:  tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# From a numpy array\n",
    "\n",
    "np_data = np.array(data)\n",
    "np_data = torch.from_numpy(np_data)\n",
    "\n",
    "print(\"Tensor from np array: \", np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor created from a previous tensor with all values as one: \n",
      " tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]]) \n",
      "\n",
      "Tensor created from a previous tensor with random values: \n",
      " tensor([[0.6212, 0.6461, 0.9722, 0.3583],\n",
      "        [0.7334, 0.3278, 0.4397, 0.3348]], dtype=torch.float64) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)                      # Retains the structure of x_data\n",
    "print(f\"Tensor created from a previous tensor with all values as one: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=float)         # Overrides the dtype of x_data\n",
    "print(f\"Tensor created from a previous tensor with random values: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand tensor: \n",
      " tensor([[0.8358, 0.9217, 0.7929],\n",
      "        [0.5806, 0.5936, 0.4244]]) \n",
      "\n",
      "ones tensor: \n",
      " tensor([[1, 1, 1],\n",
      "        [1, 1, 1]]) \n",
      "\n",
      "zeros tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape, dtype=int)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"rand tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"ones tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"zeros tensor: \\n {zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand tensor: \n",
      " tensor([[0.8097, 0.3604, 0.2458],\n",
      "        [0.6434, 0.0731, 0.0381]]) \n",
      "\n",
      "ones tensor: \n",
      " tensor([[1, 1, 1],\n",
      "        [1, 1, 1]]) \n",
      "\n",
      "zeros tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape, dtype=int)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"rand tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"ones tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"zeros tensor: \\n {zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tensor:  torch.Size([2, 3])\n",
      "dtype of tensor:  torch.float32\n",
      "device on of tenosr:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Attributs of a tensor\n",
    "\n",
    "att_tensor = torch.rand((2, 3))\n",
    "\n",
    "print(\"shape of tensor: \", att_tensor.shape)\n",
    "print(\"dtype of tensor: \", att_tensor.dtype)\n",
    "print(\"device on of tenosr: \", att_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tensor:  torch.Size([2, 3])\n",
      "dtype of tensor:  torch.float32\n",
      "device on of tenosr:  cpu\n"
     ]
    }
   ],
   "source": [
    "att_tensor = torch.rand(2, 3)\n",
    "\n",
    "print(\"shape of tensor: \", att_tensor.shape)\n",
    "print(\"dtype of tensor: \", att_tensor.dtype)\n",
    "print(\"device on of tenosr: \", att_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    att_tensor = att_tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:  tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "First row: \n",
      " tensor([1, 2, 3]) \n",
      "\n",
      "First column: \n",
      " tensor([1, 4]) \n",
      "\n",
      "Last column: \n",
      " tensor([3, 6]) \n",
      "\n",
      "Second way of printing last coloumn:  tensor([3, 6])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"tensor: \", tensor)\n",
    "print(f\"First row: \\n {tensor[0]} \\n\")\n",
    "print(f\"First column: \\n {tensor[:, 0]} \\n\")\n",
    "print(f\"Last column: \\n {tensor[..., -1]} \\n\")\n",
    "print(\"Second way of printing last coloumn: \", tensor[..., -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_tensor = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "\n",
    "join_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 5, 6, 7, 8, 5, 6, 7, 8]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_tensor = torch.cat([join_tensor, join_tensor, join_tensor], dim=1)\n",
    "\n",
    "joined_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8],\n",
       "        [1, 2, 3, 4],\n",
       "        [5, 6, 7, 8],\n",
       "        [1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_tensor1 = torch.cat([join_tensor, join_tensor, join_tensor], dim=0)\n",
    "\n",
    "\n",
    "joined_tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y1: \n",
      " tensor([[4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.]]) \n",
      "\n",
      "Y2: \n",
      " tensor([[4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.]]) \n",
      "\n",
      "Y3: \n",
      " tensor([[4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To perform matrix multiplication\n",
    "\n",
    "tensor = torch.ones(4, 4)\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "print(f\"Y1: \\n {y1} \\n\")\n",
    "print(f\"Y2: \\n {y2} \\n\")\n",
    "print(f\"Y3: \\n {y3} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1: \n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      "\n",
      "z2: \n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      "\n",
      "z3: \n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To perform element wise multiplication\n",
    "\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(z1)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "print(f\"z1: \\n {z1} \\n\")\n",
    "print(f\"z2: \\n {z2} \\n\")\n",
    "print(f\"z3: \\n {z3} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg item is: 16.0 and its type is: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "\n",
    "print(f\"agg item is: {agg_item} and its type is: {type(agg_item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# in-place addition operation\n",
    "\n",
    "print(tensor)\n",
    "\n",
    "tensor.add_(5)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:  tensor([1., 1., 1., 1.])\n",
      "numpy:  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(4)\n",
    "print(\"tensor: \", t)\n",
    "n = t.numpy()\n",
    "print(\"numpy: \", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:  tensor([6., 6., 6., 6.])\n",
      "numpy:  [6. 6. 6. 6.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(5)\n",
    "print(\"tensor: \", t)\n",
    "print(\"numpy: \", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy:  [1. 1. 1. 1. 1.]\n",
      "tensor:  tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "nu = np.ones(5)\n",
    "te = torch.from_numpy(nu)\n",
    "print(\"numpy: \", nu)\n",
    "print(\"tensor: \", te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy:  [2. 2. 2. 2. 2.]\n",
      "tensor:  tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.add(nu, 1, out=nu)\n",
    "print(\"numpy: \", nu)\n",
    "print(\"tensor: \", te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.arange(1, 16).reshape((3, 5, ))\n",
    "\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.tensor([[0, 1, 2]])\n",
    "\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = torch.zeros(3, 5, dtype=src.dtype)\n",
    "\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 2, 0, 0, 0],\n",
       "        [0, 0, 3, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.scatter_(0, idx, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 0, 0],\n",
       "        [0, 2, 0, 0, 0],\n",
       "        [0, 0, 3, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.scatter_(1, idx, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [1, 2, 3],\n",
       "        [2, 3, 4]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2 = torch.tensor([[0, 1, 2], [1, 2, 3], [2, 3, 4]])\n",
    "\n",
    "idx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  0,  0],\n",
       "        [ 0,  6,  7,  8,  0],\n",
       "        [ 0,  0, 11, 12, 13]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.scatter_(1, idx2, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n",
      "tensor([[0, 1]])\n"
     ]
    }
   ],
   "source": [
    "p = torch.arange(1, 11).reshape(2, 5)\n",
    "q = torch.tensor([[0, 1]])\n",
    "print(p)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.zeros(2, 5, dtype=p.dtype)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 2, 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.scatter_(0, q, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 0, 0, 0, 3],\n",
       "        [7, 3, 0, 2, 5],\n",
       "        [0, 6, 5, 7, 0],\n",
       "        [0, 0, 4, 0, 0],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([ [4, 3, 5, 2, 3], [7, 6, 4, 7, 5], [6, 9, 0, 5, 7], [4, 6, 5, 8, 3], [2, 4, 3, 7, 5] ])\n",
    "i = torch.tensor([ [0, 1, 2, 1, 0], [1, 2, 3, 2, 1] ])\n",
    "g = torch.zeros(5, 5, dtype=y.dtype).scatter_(0, i, y)\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 3, 5, 2, 3],\n",
       "        [5, 7, 4, 6, 7],\n",
       "        [5, 0, 6, 9, 7],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([ [4, 3, 5, 2, 3], [7, 6, 4, 7, 5], [6, 9, 0, 5, 7], [4, 6, 5, 8, 3], [2, 4, 3, 7, 5] ])\n",
    "i = torch.tensor([ [0, 1, 2, 3, 4], [4, 3, 2, 1, 0], [2, 3, 1, 0, 4] ])\n",
    "g = torch.zeros(5, 5, dtype=y.dtype).scatter_(1, i, y)\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 100,   0,   0,   0,   0],\n",
       "        [  0,   0, 106,   0,   0,   0],\n",
       "        [  0,   0,   0, 112,   0,   0],\n",
       "        [  0,   0,   0,   0, 118,   0],\n",
       "        [  0,   0,   0,   0,   0, 124]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.arange(100, 130).reshape(5, 6)\n",
    "indx = torch.tensor([ [1], [2], [3], [4], [5] ])\n",
    "srcout = torch.zeros(5, 6, dtype=src.dtype).scatter_(1, indx, src)\n",
    "\n",
    "srcout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.zeros(10)\n",
    "indx = torch.tensor([5])\n",
    "srcout = torch.zeros(10, dtype=src.dtype).scatter_(0, indx, value=1)\n",
    "\n",
    "srcout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([1., 1., 1., 1., 1.])\n",
      "Expected output:  tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5)\n",
    "y = torch.zeros(3)\n",
    "\n",
    "print(\"Input: \", x)\n",
    "print(\"Expected output: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "\n",
    "z = torch.matmul(x, w) + b\n",
    "\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:  tensor([[-1.1845e+00, -4.8193e-01,  7.0581e-04],\n",
      "        [ 2.1177e-01,  1.7791e+00,  2.7063e-01],\n",
      "        [-1.6361e+00, -1.5310e+00, -1.7240e+00],\n",
      "        [-4.4995e-01, -7.8874e-02, -8.1305e-01],\n",
      "        [-1.5742e+00, -2.7898e-02,  1.1898e+00]], requires_grad=True)\n",
      "\n",
      "bias:  tensor([ 0.2205, -0.3941,  1.8157], requires_grad=True)\n",
      "\n",
      "z:  tensor([-4.4124, -0.7346,  0.7398], grad_fn=<AddBackward0>)\n",
      "\n",
      "loss:  tensor(0.5113, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"weights: \", w)\n",
    "print(\"\\nbias: \", b)\n",
    "\n",
    "print(\"\\nz: \", z)\n",
    "print(\"\\nloss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z: <AddBackward0 object at 0x7fd1e42c68f0>\n",
      "Gradient function for loss: <BinaryCrossEntropyWithLogitsBackward0 object at 0x7fd1e42c7c40>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient function for z: {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss: {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradients of parameter set w: \u001b[39m\u001b[38;5;124m\"\u001b[39m, w\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Gradients of parameter set b: \u001b[39m\u001b[38;5;124m\"\u001b[39m, b\u001b[38;5;241m.\u001b[39mgrad)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "\n",
    "print(\"Gradients of parameter set w: \", w.grad)\n",
    "print(\"\\n Gradients of parameter set b: \", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
