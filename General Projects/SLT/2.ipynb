{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 00:17:59.473419: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 00:17:59.500347: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-10 00:17:59.500378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-10 00:17:59.501179: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 00:17:59.505993: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-10 00:18:00.313106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-03-10 00:18:01.549701: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-10 00:18:01.649475: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-10 00:18:01.649672: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-10 00:18:01.651115: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-10 00:18:01.651238: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-10 00:18:01.651304: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-10 00:18:01.721763: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-10 00:18:01.722167: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-10 00:18:01.722416: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-10 00:18:01.723042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2006 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741546083.204219   17417 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741546083.234091   17549 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2025-03-10 00:18:03.839350: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-03-10 00:18:03.959494: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "Shape of prediction\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Shape of prediction_Values:  (1,)\n",
      "prediction values:  [16]\n",
      "['H']\n",
      "H\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Shape of prediction\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Shape of prediction_Values:  (1,)\n",
      "prediction values:  [16]\n",
      "['H']\n",
      "H\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Shape of prediction\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Shape of prediction_Values:  (1,)\n",
      "prediction values:  [16]\n",
      "['H']\n",
      "H\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Shape of prediction\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Shape of prediction_Values:  (1,)\n",
      "prediction values:  [16]\n",
      "['H']\n",
      "H\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "Shape of prediction\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Shape of prediction_Values:  (1,)\n",
      "prediction values:  [16]\n",
      "['H']\n",
      "H\n",
      "1/1 [==============================] - 1s 667ms/step\n",
      "Shape of prediction\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Shape of prediction_Values:  (1,)\n",
      "prediction values:  [16]\n",
      "['H']\n",
      "H\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math as math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HandTrackingDynamic:\n",
    "    def __init__(self, mode=False, maxHands=2, detectionCon=0.5, trackCon=0.5):\n",
    "        self.__mode__   =  mode\n",
    "        self.__maxHands__   =  maxHands\n",
    "        self.__detectionCon__   =   detectionCon\n",
    "        self.__trackCon__   =   trackCon\n",
    "        self.handsMp = mp.solutions.hands\n",
    "        self.hands = self.handsMp.Hands()\n",
    "        self.mpDraw= mp.solutions.drawing_utils\n",
    "        self.tipIds = [4, 8, 12, 16, 20]\n",
    "\n",
    "    def findFingers(self, frame, draw=True):\n",
    "        imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)  \n",
    "        if self.results.multi_hand_landmarks: \n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(frame, handLms,self.handsMp.HAND_CONNECTIONS)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def findPosition( self, frame, handNo=0, draw=True):\n",
    "        xList =[]\n",
    "        yList =[]\n",
    "        bbox = []\n",
    "        self.lmsList=[]\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "            \n",
    "                h, w, c = frame.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                xList.append(cx)\n",
    "                yList.append(cy)\n",
    "                self.lmsList.append([id, cx, cy])\n",
    "                if draw:\n",
    "                    cv2.circle(frame,  (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "            xmin, xmax = min(xList), max(xList)\n",
    "            ymin, ymax = min(yList), max(yList)\n",
    "            bbox = xmin, ymin, xmax, ymax\n",
    "            print( \"Hands Keypoint\")\n",
    "            print(bbox)\n",
    "            if draw:\n",
    "                cv2.rectangle(frame, (xmin - 20, ymin - 20),(xmax + 20, ymax + 20),\n",
    "                               (0, 255 , 0) , 2)\n",
    "\n",
    "        return self.lmsList, bbox\n",
    "    \n",
    "    def findFingerUp(self):\n",
    "         fingers=[]\n",
    "\n",
    "         if self.lmsList[self.tipIds[0]][1] > self.lmsList[self.tipIds[0]-1][1]:\n",
    "              fingers.append(1)\n",
    "         else:\n",
    "              fingers.append(0)\n",
    "\n",
    "         for id in range(1, 5):            \n",
    "              if self.lmsList[self.tipIds[id]][2] < self.lmsList[self.tipIds[id]-2][2]:\n",
    "                   fingers.append(1)\n",
    "              else:\n",
    "                   fingers.append(0)\n",
    "        \n",
    "         return fingers\n",
    "\n",
    "    def findDistance(self, p1, p2, frame, draw= True, r=15, t=3):\n",
    "         \n",
    "        x1 , y1 = self.lmsList[p1][1:]\n",
    "        x2, y2 = self.lmsList[p2][1:]\n",
    "        cx , cy = (x1+x2)//2 , (y1 + y2)//2\n",
    "\n",
    "        if draw:\n",
    "              cv2.line(frame,(x1, y1),(x2,y2) ,(255,0,255), t)\n",
    "              cv2.circle(frame,(x1,y1),r,(255,0,255),cv2.FILLED)\n",
    "              cv2.circle(frame,(x2,y2),r, (255,0,0),cv2.FILLED)\n",
    "              cv2.circle(frame,(cx,cy), r,(0,0.255),cv2.FILLED)\n",
    "        len= math.hypot(x2-x1,y2-y1)\n",
    "\n",
    "        return len, frame , [x1, y1, x2, y2, cx, cy]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_dir = \"/home/abhinav/Documents/Work/2 Hobby_projects/Models\"\n",
    "\n",
    "path_to_saved_arch = os.path.join(model_dir, \"SLT_Recognition\")\n",
    "\n",
    "model = load_model(path_to_saved_arch)\n",
    "\n",
    "class_names = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \n",
    "               \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"x\", \"Y\", \"z\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "        \n",
    "        ctime=0\n",
    "        ptime=0\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        detector = HandTrackingDynamic()\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Cannot open camera\")\n",
    "            exit()\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            nframe = tf.image.resize(frame, [200, 200])\n",
    "            \n",
    "            nframe = tf.expand_dims(nframe, 0)\n",
    "            # conversion of BGR to grayscale is necessary to apply this operation\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # adaptive thresholding to use different threshold \n",
    "\n",
    "            Thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                                cv2.THRESH_BINARY_INV, 11, 2)\n",
    "            prediction = model.predict(nframe)\n",
    "            print(\"Shape of prediction\")\n",
    "            print(prediction)\n",
    "            prediction_values = np.argmax(prediction, axis=-1)\n",
    "            print(\"Shape of prediction_Values: \", prediction_values.shape)\n",
    "            print(\"prediction values: \", prediction_values)\n",
    "            c = []\n",
    "            for i in prediction_values:\n",
    "                c.append(class_names[i])\n",
    "            print(c)\n",
    "\n",
    "            prediction_act_values = c[0]\n",
    "            print(prediction_act_values)\n",
    "            cv2.putText(frame,prediction_act_values,(105,105),cv2.FONT_HERSHEY_COMPLEX_SMALL,2,(100,0,255))\n",
    "\n",
    "\n",
    "            frame = detector.findFingers(frame)\n",
    "            lmsList = detector.findPosition(frame)\n",
    "            # if len(lmsList)!=0:\n",
    "                #print(lmsList[0])\n",
    "\n",
    "            ctime = time.time()\n",
    "            fps =1/(ctime-ptime)\n",
    "            ptime = ctime\n",
    "\n",
    "            cv2.putText(frame, str(int(fps)), (10,70), cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)\n",
    " \n",
    "            #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imshow('frame', frame)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "            main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
