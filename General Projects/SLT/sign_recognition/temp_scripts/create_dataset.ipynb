{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Renames all files of a folder\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# c = 0\n",
    "\n",
    "# directory = \"/home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data\"\n",
    "# model_path = \"/home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/runs/detect/train15/weights/best.pt\"\n",
    "# model = YOLO(model_path)\n",
    "\n",
    "# for folder in glob.glob(f\"{directory}/*\"):\n",
    "#     # Open file\n",
    "#     # print(\"Folder: \", folder)\n",
    "#     if folder.split(\"/\")[-1] == \"22\":\n",
    "#         for images in os.listdir(folder):\n",
    "#             # check if the image ends with png\n",
    "#             image_path = folder + \"/\" + images\n",
    "#             print(\"image_path : \", image_path)\n",
    "#             results = model(image_path)\n",
    "#             print(results)\n",
    "#             for result in results:\n",
    "#                 print(\"image:\")\n",
    "#                 print(result.orig_img)\n",
    "#                 print(\"result.boxes\")\n",
    "#                 print(result.boxes.cpu().numpy())\n",
    "#                 print(\"\\n\\n\\n\")\n",
    "#                 print(\"Required results:\")\n",
    "#                 print(\"Bounding boxes of right hand\")\n",
    "#                 print(result.boxes[0].xyxy.cpu().numpy())\n",
    "#                 print(\"Bounding boxes for left hand\")\n",
    "#                 print(result.boxes[1].xyxy.cpu().numpy())\n",
    "#                 print(\"In total result.boxes\")\n",
    "#                 print(result.boxes)\n",
    "#                 print(\"\\n\\nresult.boxes[0]\")\n",
    "#                 print(result.boxes[0])\n",
    "#                 print(\"\\n\\nresult.boxes[1]\")\n",
    "#                 print(result.boxes[1])\n",
    "#                 print(\"\\n\\nresult.boxes[2]\")\n",
    "#                 print(result.boxes[2])\n",
    "#                 print(\"The class of first bounding box:\")\n",
    "#                 print(int(result.boxes[0].cls.cpu().numpy()[0]))\n",
    "#             results[0].show()\n",
    "\n",
    "#             # result[1] is not there\n",
    "#             # print(\"\\n\\n\\nresults[1]\")\n",
    "#             # print(results[1])\n",
    "#             break\n",
    "#         break\n",
    "#     else:\n",
    "#         continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_short(x, n):\n",
    "    x = str(x)\n",
    "    al = x.split(\".\")\n",
    "    c = al[0] + \".\" + al[1][:n]\n",
    "    return float(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder:  /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/165.jpg: 192x224 1 Right_Hand, 8.4ms\n",
      "Speed: 0.5ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/198.jpg: 192x224 (no detections), 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/246.jpg: 192x224 1 Right_Hand, 6.7ms\n",
      "Speed: 1.6ms preprocess, 6.7ms inference, 2.2ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/17.jpg: 192x224 1 Right_Hand, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 2.2ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/295.jpg: 192x224 3 Right_Hands, 10.5ms\n",
      "Speed: 0.9ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741325498.991405    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.010026    9419 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.034975    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.054290    9436 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.085275    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.106591    9453 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.145112    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.164691    9470 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.192930    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/214.jpg: 192x224 1 Left_Hand, 14.1ms\n",
      "Speed: 1.2ms preprocess, 14.1ms inference, 1.3ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  269\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/100.jpg: 192x224 1 Left_Hand, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 1.4ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  238\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/37.jpg: 192x224 (no detections), 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 0.3ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/195.jpg: 192x224 (no detections), 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741325499.211300    9487 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.250548    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.269228    9504 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.305228    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.325518    9521 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.353267    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.368278    9538 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.394979    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.414256    9555 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/123.jpg: 192x224 1 Right_Hand, 14.1ms\n",
      "Speed: 0.8ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/166.jpg: 192x224 1 Right_Hand, 13.6ms\n",
      "Speed: 2.5ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/244.jpg: 192x224 1 Right_Hand, 8.9ms\n",
      "Speed: 2.5ms preprocess, 8.9ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/67.jpg: 192x224 (no detections), 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/269.jpg: 192x224 (no detections), 10.2ms\n",
      "Speed: 1.1ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741325499.454886    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.485842    9572 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.521703    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.543087    9589 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.578607    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.603868    9606 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.639839    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.660293    9623 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/224.jpg: 192x224 1 Left_Hand, 1 Right_Hand, 6.0ms\n",
      "Speed: 0.7ms preprocess, 6.0ms inference, 1.7ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  296\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/21.jpg: 192x224 1 Right_Hand, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 2.9ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/120.jpg: 192x224 1 Right_Hand, 8.9ms\n",
      "Speed: 0.8ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/225.jpg: 192x224 1 Right_Hand, 19.8ms\n",
      "Speed: 1.1ms preprocess, 19.8ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741325499.692226    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.712431    9640 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.736213    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.758023    9657 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.783351    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.807212    9674 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.843058    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.864595    9691 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.908450    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/273.jpg: 192x224 (no detections), 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/137.jpg: 192x224 (no detections), 9.9ms\n",
      "Speed: 1.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/238.jpg: 192x224 1 Right_Hand, 7.5ms\n",
      "Speed: 0.8ms preprocess, 7.5ms inference, 2.9ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/112.jpg: 192x224 (no detections), 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741325499.930677    9708 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325499.960428    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325499.978719    9725 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325500.014023    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325500.031692    9742 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325500.061446    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325500.084297    9759 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325500.108561    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325500.128781    9776 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/262.jpg: 192x224 1 Right_Hand, 18.7ms\n",
      "Speed: 0.9ms preprocess, 18.7ms inference, 1.9ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n",
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/271.jpg: 192x224 (no detections), 17.2ms\n",
      "Speed: 1.6ms preprocess, 17.2ms inference, 3.3ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741325500.177152    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325500.210860    9793 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741325500.273776    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325500.308056    9810 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/101.jpg: 192x224 (no detections), 131.3ms\n",
      "Speed: 34.0ms preprocess, 131.3ms inference, 23.3ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741325500.587209    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325500.625718    9827 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/19/61.jpg: 192x224 (no detections), 11866.4ms\n",
      "Speed: 78.2ms preprocess, 11866.4ms inference, 213.3ms postprocess per image at shape (1, 3, 192, 224)\n",
      "Found left and right bb\n",
      "\n",
      "\n",
      "\n",
      "Going to find keypoints: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Taking element of cropped images\n",
      "Len of the taken cropped image:  0\n",
      "Image\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741325512.954504    8541 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741325513.006057    9869 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    }
   ],
   "source": [
    "directory = \"/home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data\"\n",
    "model_path = \"/home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/runs/detect/train15/weights/best.pt\"\n",
    "\n",
    "\n",
    "\n",
    "# Global variables\n",
    "width = 640\n",
    "height = 480\n",
    "resize_dim = 300\n",
    "c = 0\n",
    "img_bb_pad = 35\n",
    "cv2_frame_size = [width, height]\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for folder in glob.glob(f\"{directory}/*\"):\n",
    "\n",
    "    print(\"Folder: \", folder)\n",
    "\n",
    "    for images in os.listdir(folder):\n",
    "\n",
    "        # Taking the image path\n",
    "\n",
    "        image_path = folder + \"/\" + images\n",
    "        print(\"Image\")\n",
    "        # print(\"image_path : \", image_path)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Process the image for hand detection\n",
    "\n",
    "        det_results = model(image_path)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # To get a padded detection coordinates( only one for left, and one for right)\n",
    "\n",
    "        left_area = 0\n",
    "        left_coord = [0, 0, 0, 0]\n",
    "        right_area = 0\n",
    "        right_coord = [0, 0, 0, 0]\n",
    "\n",
    "        for box in det_results[0].boxes:\n",
    "\n",
    "            # Getting the basics\n",
    "\n",
    "            bb = box.xyxy.cpu().numpy()[0]\n",
    "            bb_class = int(box.cls.cpu().numpy()[0])\n",
    "            bb_class_str = \"Right_Hand\" if bb_class else \"Left_Hand\"\n",
    "            bb_area = (bb[2] - bb[0])*(bb[3]-bb[1])\n",
    "            # print(\"Bounding box classification: \", bb_class_str)\n",
    "            # print(\"Bounding box coordinates: \", bb)\n",
    "            # print(\"Bounding box area: \", bb_area, \"\\n\")\n",
    "            if bb_class_str == \"Left_Hand\":\n",
    "                if bb_area > left_area:\n",
    "                    left_area = bb_area\n",
    "\n",
    "                    bb_pad = [bb[0]-img_bb_pad, bb[1]-img_bb_pad, bb[2]+img_bb_pad, bb[3]+img_bb_pad]\n",
    "                    final_bb_pad = [max(bb_pad[0], bb[0]), max(bb_pad[1], bb[1]), min(bb_pad[2], bb[2]), min(bb_pad[3], bb[3])]\n",
    "\n",
    "                    left_coord = final_bb_pad\n",
    "            else:\n",
    "                if bb_area > right_area:\n",
    "                    right_area = bb_area\n",
    "\n",
    "                    bb_pad = [bb[0]-img_bb_pad, bb[1]-img_bb_pad, bb[2]+img_bb_pad, bb[3]+img_bb_pad]\n",
    "                    final_bb_pad = [max(bb_pad[0], bb[0]), max(bb_pad[1], bb[1]), min(bb_pad[2], bb[2]), min(bb_pad[3], bb[3])]\n",
    "\n",
    "                    right_coord = final_bb_pad\n",
    "\n",
    "        # print(\"Final two bounding box:\")\n",
    "        # print(\"Left hand coordinates:\")\n",
    "        # print(left_coord)\n",
    "        # print(\"\\n\")\n",
    "        # print(\"Right hand coordinates:\")\n",
    "        # print(right_coord)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #To crop, resize, and if needed to plot the padded detection boxes\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        image_with_new_bounding = cv2.rectangle(\n",
    "                                                img, \n",
    "                                                ( int(left_coord[0]), int(left_coord[1]) ),\n",
    "                                                ( int(left_coord[2]), int(left_coord[3]) ),\n",
    "                                                color=(0, 0, 255),\n",
    "                                                thickness=2)\n",
    "        image_with_new_bounding = cv2.rectangle(\n",
    "                                                img, \n",
    "                                                ( int(right_coord[0]), int(right_coord[1]) ),\n",
    "                                                ( int(right_coord[2]), int(right_coord[3]) ),\n",
    "                                                color=(0, 255, 0),\n",
    "                                                thickness=2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Found left and right bb\")\n",
    "        cropped_images = []\n",
    "        cropped_images.append(img[ int(left_coord[1]) : int( left_coord[3] ), int( left_coord[0] ) : int( left_coord[2] )] )\n",
    "        cropped_images.append(img[ int(right_coord[1]) : int( right_coord[3] ), int( right_coord[0] ) : int( right_coord[2] )] )\n",
    "\n",
    "\n",
    "        l1 = len(cropped_images[0])\n",
    "        r1 = len(cropped_images[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # To get the landmarks of each hand for each image\n",
    "\n",
    "        c += 1\n",
    "        precision = 3\n",
    "        temp_data = []\n",
    "        left_data = []\n",
    "        right_data = []\n",
    "        fin_data = []\n",
    "        fin_label = []\n",
    "\n",
    "\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "        try:\n",
    "\n",
    "            print(\"\\n\\n\\nGoing to find keypoints: \\n\\n\\n\\n\\n\\n\")\n",
    "            for i in cropped_images:\n",
    "                print(\"Taking element of cropped images\")\n",
    "                print(\"Len of the taken cropped image: \", len(i))\n",
    "                print(\"Is the cropped image an empty list: \", \"Yes\" if i == [] else \"No\")\n",
    "                try:\n",
    "                    \n",
    "                    file_path = \"data1/left\" + str(c) + \".png\"\n",
    "                    resized = cv2.resize(cropped_images[0], (resize_dim, resize_dim))\n",
    "                    results = hands.process(resized)\n",
    "                    left_hand_lm = results.multi_hand_landmarks[0]\n",
    "\n",
    "                    for i in range(21):\n",
    "                        # Left hand points\n",
    "                        x1 = get_short(left_hand_lm.landmark[i].x, precision)\n",
    "                        y1 = get_short(left_hand_lm.landmark[i].y, precision)\n",
    "                        z1 = get_short(left_hand_lm.landmark[i].z, precision)\n",
    "\n",
    "                        temp_data.append([x1, y1, z1])\n",
    "\n",
    "                    for i in temp_data:\n",
    "                        for j in range(3):\n",
    "                            left_data.append(i[j])\n",
    "\n",
    "                    cv2.imwrite(file_path, resized)\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "\n",
    "                    file_path = \"data1/right\" + str(c) + \".png\"\n",
    "                    resized = cv2.resize(cropped_images[1], (resize_dim, resize_dim))\n",
    "\n",
    "                    results = hands.process(resized)\n",
    "                    right_hand_lm = results.multi_hand_landmarks[1]\n",
    "\n",
    "                    for i in range(21):\n",
    "                        # Left hand points\n",
    "                        x1 = get_short(right_hand_lm.landmark[i].x, precision)\n",
    "                        y1 = get_short(right_hand_lm.landmark[i].y, precision)\n",
    "                        z1 = get_short(right_hand_lm.landmark[i].z, precision)\n",
    "\n",
    "                        temp_data.append([x1, y1, z1])\n",
    "\n",
    "                    for i in temp_data:\n",
    "                        for j in range(3):\n",
    "                            right_data.append(i[j])\n",
    "\n",
    "                    # Right hand is detected\n",
    "                    # print(\"right detected\")\n",
    "\n",
    "                    cv2.imwrite(file_path, resized)\n",
    "                \n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            if left_data != []:\n",
    "                for i in left_data:\n",
    "                    fin_data.append(i)\n",
    "            else:\n",
    "                for i in range(63):\n",
    "                    fin_data.append(0)\n",
    "            \n",
    "            if right_data != []:\n",
    "                for i in right_data:\n",
    "                    fin_data.append(i)\n",
    "            else:\n",
    "                for i in range(63):\n",
    "                    fin_data.append(0)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "        fin_label.append(folder.split(\"/\")[-1])\n",
    "\n",
    "\n",
    "        print(\"Final data dimension: (Should be 126): \", len(fin_data))\n",
    "        print(\"\\n\\n fin_data:\\n\", fin_data)\n",
    "        print(\"Final label dimension: (should be 1): \", len(fin_label))\n",
    "        print(\"\\n\\n fin_label:\\n\", fin_label)\n",
    "\n",
    "        data.append(fin_data)\n",
    "        labels.append(fin_label)\n",
    "\n",
    "        # if l1 != 0:\n",
    "        #     # Left hand is detected\n",
    "        #     # print(\"left detected\")\n",
    "        #     file_path = \"data1/left\" + str(c) + \".png\"\n",
    "        #     resized = cv2.resize(cropped_images[0], (resize_dim, resize_dim))\n",
    "\n",
    "        #     results = hands.process(resized)\n",
    "        #     left_hand_lm = results.multi_hand_landmarks[0]\n",
    "\n",
    "        #     for i in range(21):\n",
    "        #         # Left hand points\n",
    "        #         x1 = get_short(left_hand_lm.landmark[i].x, precision)\n",
    "        #         y1 = get_short(left_hand_lm.landmark[i].y, precision)\n",
    "        #         z1 = get_short(left_hand_lm.landmark[i].z, precision)\n",
    "\n",
    "        #         temp_data.append([x1, y1, z1])\n",
    "\n",
    "        #     for i in temp_data:\n",
    "        #         for j in range(3):\n",
    "        #             fin_data.append(i[j])\n",
    "\n",
    "        #     cv2.imwrite(file_path, resized)\n",
    "        # else:\n",
    "\n",
    "        #     for i in range(63):\n",
    "        #         fin_data.append(0)\n",
    "        #     # print(\"left not detected\")\n",
    "        # if r1 != 0:\n",
    "\n",
    "        #     file_path = \"data1/right\" + str(c) + \".png\"\n",
    "        #     resized = cv2.resize(cropped_images[1], (resize_dim, resize_dim))\n",
    "\n",
    "        #     results = hands.process(resized)\n",
    "        #     right_hand_lm = results.multi_hand_landmarks[1]\n",
    "\n",
    "        #     for i in range(21):\n",
    "        #         # Left hand points\n",
    "        #         x1 = get_short(right_hand_lm.landmark[i].x, precision)\n",
    "        #         y1 = get_short(right_hand_lm.landmark[i].y, precision)\n",
    "        #         z1 = get_short(right_hand_lm.landmark[i].z, precision)\n",
    "\n",
    "        #         temp_data.append([x1, y1, z1])\n",
    "\n",
    "        #     for i in temp_data:\n",
    "        #         for j in range(3):\n",
    "        #             fin_data.append(i[j])\n",
    "\n",
    "        #     # Right hand is detected\n",
    "        #     # print(\"right detected\")\n",
    "\n",
    "        #     cv2.imwrite(file_path, resized)\n",
    "        # else:\n",
    "        #     for i in range(63):\n",
    "        #         fin_data.append(0)\n",
    "        #     # print(\"right not detected\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # # fin_data\n",
    "        # print(\"Len of fin data: should be 126: \", len(fin_data))\n",
    "        # fin_label.append(folder.split(\"/\")[-1])\n",
    "        # print(\"len of final label: \", len(fin_label), \"   its: \", fin_label[0])\n",
    "        # try:\n",
    "        #     # file_path = \"data1/\" + str(c) +  \"left.png\"\n",
    "        #     file_path = \"data1/left\" + images\n",
    "        #     resized = cv2.resize(cropped_images[0], (resize_dim, resize_dim))\n",
    "        #     temp_data.append(left_area)\n",
    "        #     cv2.imwrite(file_path, resized)\n",
    "        # except:\n",
    "        #     temp_data.append(\"0\")\n",
    "        #     continue\n",
    "        # try:\n",
    "        #     # file_path = \"data1/\" + str(c) + \"right.png\"\n",
    "        #     file_path = \"data1/right\" + images\n",
    "        #     resized = cv2.resize(cropped_images[1], (resize_dim, resize_dim))\n",
    "        #     temp_data.append(right_area)\n",
    "        #     cv2.imwrite(file_path, resized)\n",
    "        # except:\n",
    "        #     temp_data.append(\"0\")\n",
    "        #     continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"finished writing\")\n",
    "        # results[0].show()\n",
    "    # else:\n",
    "        \n",
    "        break\n",
    "    if folder.split(\"/\")[-1] == str(3):\n",
    "        break\n",
    "    # else:\n",
    "    #     continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['19']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_to_export' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mlabel_to_export\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_to_export' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(label_to_export))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
