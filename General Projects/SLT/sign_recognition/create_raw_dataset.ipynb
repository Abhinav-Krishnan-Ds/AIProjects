{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 23:59:57.715743: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-09 23:59:57.743103: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-09 23:59:57.743163: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-09 23:59:57.744157: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-09 23:59:57.748965: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-09 23:59:58.427801: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data\"\n",
    "csv_file_path = \"/home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/out_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(csv_file_path, \"w\") as f:\n",
    "#     print(\"File created\")\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 3\n",
    "min_det_conf = 0.2\n",
    "min_track_conf = 0.2\n",
    "num_images_to_process = 2\n",
    "block_data_to_process = 10\n",
    "sleep_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_short(x, n):\n",
    "    x = str(x)\n",
    "    al = x.split(\".\")\n",
    "    c = al[0] + \".\" + al[1][:n]\n",
    "    return float(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_elements = [i for i in range(0, 300, num_images_to_process)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_elements = [start_elements[i:i + block_data_to_process] for i in range(0, len(start_elements), block_data_to_process)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 14\n",
    "start_element = [start_elements[p]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741544999.301411   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741544999.334537   14050 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "/home/abhinav/.local/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "I0000 00:00:1741544999.393599   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741544999.402526   14082 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741544999.454291   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741544999.464549   14099 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741544999.524001   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741544999.537043   14116 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sleep for some time\n",
      "Number of images completed processing :  282\n",
      "Starting again\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sleep for some time\n",
      "Number of images completed processing :  284\n",
      "Starting again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741544999.603754   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741544999.618544   14133 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741544999.684114   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741544999.701341   14150 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741544999.767050   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741544999.779834   14167 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sleep for some time\n",
      "Number of images completed processing :  286\n",
      "Starting again\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sleep for some time\n",
      "Number of images completed processing :  288\n",
      "Starting again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741544999.851947   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741544999.880610   14184 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741544999.944270   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741544999.958816   14201 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741545000.018350   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.031705   14218 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741545000.084016   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.098193   14235 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sleep for some time\n",
      "Number of images completed processing :  290\n",
      "Starting again\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sleep for some time\n",
      "Number of images completed processing :  292\n",
      "Starting again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741545000.158109   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.171497   14252 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741545000.228541   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.242112   14269 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741545000.296248   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.313425   14286 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sleep for some time\n",
      "Number of images completed processing :  294\n",
      "Starting again\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sleep for some time\n",
      "Number of images completed processing :  296\n",
      "Starting again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741545000.382280   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.395798   14303 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741545000.448500   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.463284   14320 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741545000.524811   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.534755   14337 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741545000.587747   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.602988   14354 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sleep for some time\n",
      "Number of images completed processing :  298\n",
      "Starting again\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sleep for some time\n",
      "Number of images completed processing :  300\n",
      "Starting again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741545000.662250   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.674373   14371 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n",
      "I0000 00:00:1741545000.732905   13960 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741545000.746826   14388 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.183.01), renderer: NVIDIA GeForce RTX 3050 Laptop GPU/PCIe/SSE2\n"
     ]
    }
   ],
   "source": [
    "# 40 is over\n",
    "folder = directory + \"/41\"\n",
    "\n",
    "c = 0\n",
    "\n",
    "for start in start_element:\n",
    "    for k in start:\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for image in range(k, k+num_images_to_process):\n",
    "\n",
    "            image_path = folder + \"/\" + str(image) + \".jpg\"\n",
    "            # print(image_path)\n",
    "\n",
    "\n",
    "            data_label = int(folder.split(\"/\")[-1])\n",
    "\n",
    "\n",
    "            mp_hands = mp.solutions.hands\n",
    "            hands = mp_hands.Hands(min_detection_confidence=min_det_conf, min_tracking_confidence=min_track_conf)\n",
    "\n",
    "\n",
    "            # image_path = \"/home/abhinav/Desktop/AIProjects/General Projects/SLT/sign_recognition/data/21/0.jpg\"\n",
    "            img = cv2.imread(image_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # plt.imshow(img)\n",
    "\n",
    "\n",
    "            results = hands.process(img)\n",
    "            # print(\"\\n\\nlen(results.multi_hand_landmarks)\", len(results.multi_hand_landmarks))\n",
    "            # print(\"\\n\\nresults.multi_hand_landmarks\", results.multi_hand_landmarks)\n",
    "            # print(\"\\n\\nlen(results.multi_handedness)\", len(results.multi_handedness))\n",
    "            # print(\"\\n\\nresults.multi_handedness\", results.multi_handedness)\n",
    "            # print(\"\\n\\n\\n\")\n",
    "\n",
    "            right_detected = False\n",
    "            left_detected = False\n",
    "\n",
    "            left_data = []\n",
    "            right_data = []\n",
    "\n",
    "            data_point = []\n",
    "\n",
    "            if results.multi_handedness is not None:\n",
    "\n",
    "                for idx, (hand, hand_label) in enumerate(zip(results.multi_hand_landmarks, results.multi_handedness)):\n",
    "                    # print(\"Detected: \", idx+1, \" hand\")\n",
    "                    # print(\"Hand classification: \", \"Right\" if hand_label.classification[0].label == \"Left\" else \"Left\")\n",
    "                    # print(\"Landmarks: \\n\")\n",
    "                    # print(\": \", hand.landmark)\n",
    "\n",
    "                    if hand_label.classification is not None:\n",
    "                        hand_class = \"Right\" if hand_label.classification[0].label == \"Left\" else \"Left\"\n",
    "\n",
    "                        if hand_class == \"Right\":\n",
    "\n",
    "                            right_detected = True\n",
    "\n",
    "                            for i in range(21):\n",
    "                                x1 = get_short(hand.landmark[i].x, precision)\n",
    "                                y1 = get_short(hand.landmark[i].y, precision)\n",
    "                                z1 = get_short(hand.landmark[i].z, precision)\n",
    "\n",
    "                                right_data.extend([x1, y1, z1])\n",
    "                            \n",
    "\n",
    "                        else:\n",
    "\n",
    "                            left_detected = True\n",
    "                        \n",
    "                            for i in range(21):\n",
    "                                x1 = get_short(hand.landmark[i].x, precision)\n",
    "                                y1 = get_short(hand.landmark[i].y, precision)\n",
    "                                z1 = get_short(hand.landmark[i].z, precision)\n",
    "\n",
    "                                left_data.extend([x1, y1, z1])\n",
    "            del results\n",
    "            del hands\n",
    "            del mp_hands\n",
    "            del img\n",
    "\n",
    "            if left_data == []:\n",
    "                left_data = [0 for i in range(63)]\n",
    "            if right_data == []:\n",
    "                right_data = [0 for i in range(63)]\n",
    "\n",
    "\n",
    "            # print(\"Right data: \", right_data)\n",
    "            # print(\"Left data: \", left_data)\n",
    "            # print(\"Label: \", data_label)\n",
    "\n",
    "            if left_data != [] or right_data != []:\n",
    "\n",
    "                data_point = [image] + left_data + right_data\n",
    "                data_point.append(data_label)\n",
    "\n",
    "                # print(\"Datat point : \", data_point)\n",
    "                data.append(data_point)\n",
    "            # break\n",
    "        \n",
    "        # Here we get 10 data points\n",
    "        # write it to csv file and close it\n",
    "        # del all the variables not used further\n",
    "\n",
    "        with open(csv_file_path, \"a\") as f:\n",
    "            for i in data:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(i)\n",
    "        f.close()\n",
    "        del data\n",
    "\n",
    "        print(\"\\n\\n\\n\\n\\n\\nSleep for some time\")\n",
    "        print(\"Number of images completed processing : \", k+num_images_to_process)\n",
    "        time.sleep(sleep_time)\n",
    "        print(\"Starting again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Images processed: \", len(data))\n",
    "# print(\"\\n#Number of features: 3 for each landmark, 21 landmarks for a hand, 1 for data label\")\n",
    "# print(\"#In total: (3*(21*2)) + 1 = 127, Let's see how much we get\")\n",
    "# print(\"\\nNumber of features of one data point(one image): \", len(data[0]))\n",
    "\n",
    "# print(\"\\nFirst 10 data points: \")\n",
    "# c = 0\n",
    "# for i in data:\n",
    "#     if c > 10:\n",
    "#         break\n",
    "#     print(i)\n",
    "#     c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed  10  number of blocks of data\n"
     ]
    }
   ],
   "source": [
    "print(\"Completed \", block_data_to_process, \" number of blocks of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
