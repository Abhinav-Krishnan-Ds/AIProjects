{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 12:45:04.047681: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-04 12:45:04.077344: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-04 12:45:04.077392: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-04 12:45:04.078362: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-04 12:45:04.084137: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-04 12:45:04.778799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n",
      "cuda_malloc_async\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 12:45:06.005073: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-04 12:45:06.038537: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-04 12:45:06.038712: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-04 12:45:06.040614: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-04 12:45:06.040809: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-04 12:45:06.040877: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-04 12:45:06.094530: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-04 12:45:06.094679: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-04 12:45:06.094836: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-04 12:45:06.094904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# GPU settings\n",
    "\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "\n",
    "# Setting gpu[0] as main device\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "# Setting memory growth\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "print(os.getenv('TF_GPU_ALLOCATOR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/home/abhinav/Documents/Work/2 Hobby_projects/Datasets/Imagenet/train_synsets\"\n",
    "valid_dir = \"/home/abhinav/Documents/Work/2 Hobby_projects/Datasets/Imagenet/valid_synsets\"\n",
    "test_dir = \"/home/abhinav/Documents/Work/2 Hobby_projects/Datasets/Imagenet/test_synsets\"\n",
    "\n",
    "model_dir = \"/home/abhinav/Documents/Work/2 Hobby_projects/Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image_height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m      2\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m,\n\u001b[1;32m      3\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m     11\u001b[0m     train_dir,\n\u001b[0;32m---> 12\u001b[0m     target_size \u001b[38;5;241m=\u001b[39m (\u001b[43mImage_height\u001b[49m, Image_width),\n\u001b[1;32m     13\u001b[0m     color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     15\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     16\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m valid_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m     21\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m valid_generator \u001b[38;5;241m=\u001b[39m valid_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m     25\u001b[0m     valid_dir,\n\u001b[1;32m     26\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(Image_height, Image_width),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image_height' is not defined"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (Image_height, Image_width),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(Image_height, Image_width),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    seed=7,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(Image_height, Image_width),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    seed=7,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples\n",
    "train_num = train_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet(Sequential):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.add(Conv2D(\n",
    "            64,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            input_shape=input_shape\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            64,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=2\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            128,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            128,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=2\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            256,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            256,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            256,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=2\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            512,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            512,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            512,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=2\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            512,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            512,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            512,\n",
    "            kernel_size=(3,3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=2\n",
    "        ))\n",
    "\n",
    "        self.add(Flatten()),\n",
    "\n",
    "        self.add(Dense(4096, activation=\"relu\"))\n",
    "        self.add(Dense(4096, activation=\"relu\"))\n",
    "        self.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "        self.compile(\n",
    "            optimizer=Adam(0.001),\n",
    "            loss = \"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 1\n",
    "Image_height = 224\n",
    "Image_width = 224\n",
    "Input_shape = (Image_width, Image_height, 3)\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "model = VGGNet(Input_shape, num_classes=num_classes)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./logs/fit\" + datetime.datetime.now().strftime(\"%d%M%Y-%H%M%S\")\n",
    "tensorboard_callbacks = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "callbacks_list = [tensorboard_callbacks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since lack of gpu power, we cant train this model in local machine, so we take step to take pretrained model\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    # steps_per_epoch=train_images_num//batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    # validation_steps=valid_images_num//batch_size,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.vgg16 import VGG16\n",
    "# vggmodel = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"layers of the model:\")\n",
    "# for la in vggmodel.layers:\n",
    "#     print(la)\n",
    "\n",
    "\n",
    "# print(\"\\n\\nlayers that we are going to set trainable to False\")\n",
    "# for layers in (vggmodel.layers)[:15]:\n",
    "#     print(layers)\n",
    "#     layers.trainable = False\n",
    "\n",
    "# X= vggmodel.layers[-2].output\n",
    "# predictions = Dense(2, activation=\"softmax\")(X)\n",
    "# model_final = Model(vggmodel.input, predictions)\n",
    "# opt = Adam(learning_rate=0.0001)\n",
    "# model_final.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=[\"accuracy\"])\n",
    "# model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
