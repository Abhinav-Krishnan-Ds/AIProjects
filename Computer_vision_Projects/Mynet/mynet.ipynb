{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 19:03:42.618651: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-03 19:03:42.770755: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-03 19:03:42.770986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-03 19:03:42.795452: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-03 19:03:42.843449: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-03 19:03:43.922541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ActivityRegularization, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from module import Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected:  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "1 Logical devices and  1 Physical devices detected\n",
      "cuda_malloc_async\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 19:03:45.986589: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 19:03:46.093579: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 19:03:46.093742: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 19:03:46.095646: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 19:03:46.095758: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 19:03:46.095820: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 19:03:46.153947: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 19:03:46.154108: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 19:03:46.154184: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 19:03:46.154250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1944 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# gpu settings\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "    print(\"GPU detected: \", gpus[0])\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], \"GPU\")\n",
    "        ldev = tf.config.list_logical_devices(\"GPU\")\n",
    "        print(len(ldev), \"Logical devices and \", len(gpus), \"Physical devices detected\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "print(os.getenv(\"TF_GPU_ALLOCATOR\"))\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/home/abhinav/Documents/2 Work/2 Hobby_projects/Datasets/Imagenet/train_synsets\"\n",
    "valid_dir = \"/home/abhinav/Documents/2 Work/2 Hobby_projects/Datasets/Imagenet/valid_synsets\"\n",
    "test_dir = \"/home/abhinav/Documents/2 Work/2 Hobby_projects/Datasets/Imagenet/test_synsets\"\n",
    "\n",
    "model_dir = \"/home/abhinav/Documents/2 Work/2 Hobby_projects/Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 20\n",
    "img_h = 128\n",
    "img_w = 128\n",
    "num_channels = 3\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyNet(Sequential):\n",
    "#     def __init__(self, input_shape, num_classes):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.add(Conv2D(\n",
    "#             70,\n",
    "#             kernel_size=(3, 3),\n",
    "#             strides=1,\n",
    "#             padding=\"valid\",\n",
    "#             kernel_initializer=\"he_normal\",\n",
    "#             input_shape=input_shape,\n",
    "#             activation=\"relu\"\n",
    "#         ))\n",
    "\n",
    "#         self.add(Conv2D(\n",
    "#             128,\n",
    "#             kernel_size=(3, 3),\n",
    "#             strides=2,\n",
    "#             padding=\"valid\",\n",
    "#             kernel_initializer=\"he_normal\",\n",
    "#             activation=\"relu\"\n",
    "#         ))\n",
    "        \n",
    "#         self.add(MaxPooling2D(\n",
    "#             pool_size=(3, 3),\n",
    "#             strides=2,\n",
    "#             padding=\"valid\",\n",
    "#             data_format=None\n",
    "#         ))\n",
    "\n",
    "#         self.add(Conv2D(\n",
    "#             256,\n",
    "#             kernel_size=(3, 3),\n",
    "#             strides=1,\n",
    "#             padding=\"valid\",\n",
    "#             kernel_initializer=\"he_normal\",\n",
    "#             activation=\"relu\"\n",
    "#         ))\n",
    "\n",
    "#         self.add(Conv2D(\n",
    "#             256,\n",
    "#             kernel_size=(3, 3),\n",
    "#             strides=1,\n",
    "#             padding=\"valid\",\n",
    "#             kernel_initializer=\"he_normal\",\n",
    "#             activation=\"relu\"\n",
    "#         ))\n",
    "\n",
    "#         self.add(MaxPooling2D(\n",
    "#             pool_size=(3, 3),\n",
    "#             strides=2,\n",
    "#             padding=\"valid\",\n",
    "#             data_format=None\n",
    "#         ))\n",
    "\n",
    "#         self.add(Conv2D(\n",
    "#             256,\n",
    "#             kernel_size=(3, 3),\n",
    "#             strides=1,\n",
    "#             padding=\"valid\",\n",
    "#             kernel_initializer=\"he_normal\",\n",
    "#             activation=\"relu\"\n",
    "#         ))\n",
    "\n",
    "#         self.add(Conv2D(\n",
    "#             512,\n",
    "#             kernel_size=(5, 5),\n",
    "#             strides=2,\n",
    "#             padding=\"valid\",\n",
    "#             kernel_initializer=\"he_normal\",\n",
    "#             activation=\"relu\"\n",
    "#         ))\n",
    "\n",
    "#         self.add(Conv2D(\n",
    "#             64,\n",
    "#             kernel_size=(5, 5),\n",
    "#             strides=2,\n",
    "#             padding=\"valid\",\n",
    "#             kernel_initializer=\"he_normal\",\n",
    "#             activation=\"relu\"\n",
    "#         ))\n",
    "\n",
    "#         # self.add(BatchNormalization(momentum=1))\n",
    "#         self.add(Flatten())\n",
    "#         # self.add(Dropout(0.5))\n",
    "#         # self.add(Dense(4096, activation=\"relu\"))\n",
    "#         self.add(Dropout(0.4))\n",
    "#         # self.add(Dense(3796, activation=\"relu\"))\n",
    "#         self.add(Dense(1000, activation=\"relu\"))\n",
    "#         self.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "#         self.compile(\n",
    "#             # optimizer=Ranger(learning_rate=0.0001),\n",
    "#             # optimizer=Ranger(learning_rate=0.000001, amsgrad=True, slow_step_size=0.8, warmup_proportion=0.3),\n",
    "#             optimizer=Adam(learning_rate=0.0001, use_ema=True, ema_momentum=1),\n",
    "#             loss=\"categorical_crossentropy\",\n",
    "#             metrics=[\"accuracy\"]\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(Sequential):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            256,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=1,\n",
    "            padding=\"valid\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            input_shape=input_shape,\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            128,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=1,\n",
    "            padding=\"valid\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "        \n",
    "        self.add(MaxPooling2D(\n",
    "            pool_size=(3, 3),\n",
    "            strides=2,\n",
    "            padding=\"valid\",\n",
    "            data_format=None\n",
    "        ))\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            128,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=1,\n",
    "            padding=\"valid\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "\n",
    "        self.add(MaxPooling2D(\n",
    "            pool_size=(3, 3),\n",
    "            strides=2,\n",
    "            padding=\"valid\",\n",
    "            data_format=None\n",
    "        ))\n",
    "\n",
    "\n",
    "        self.add(Conv2D(\n",
    "            32,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2,\n",
    "            padding=\"valid\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            activation=\"relu\"\n",
    "        ))\n",
    "\n",
    "        # self.add(BatchNormalization(momentum=1))\n",
    "        self.add(Flatten())\n",
    "        # self.add(Dropout(0.5))\n",
    "        # self.add(Dense(4096, activation=\"relu\"))\n",
    "        self.add(Dropout(0.4))\n",
    "        # self.add(Dense(3796, activation=\"relu\"))\n",
    "        self.add(Dense(1000, activation=\"relu\"))\n",
    "        self.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "        self.compile(\n",
    "            # optimizer=Ranger(learning_rate=0.0001),\n",
    "            # optimizer=Ranger(learning_rate=0.000001, amsgrad=True, slow_step_size=0.8, warmup_proportion=0.3),\n",
    "            optimizer=Adam(learning_rate=0.0001, use_ema=True, ema_momentum=1),\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 256)     7168      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 124, 124, 128)     295040    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 61, 61, 128)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 59, 59, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 29, 29, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 32)        36896     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              6273000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 3003      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6762691 (25.80 MB)\n",
      "Trainable params: 6762691 (25.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyNet((img_w, img_h, num_channels), num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2495 images belonging to 3 classes.\n",
      "Found 1071 images belonging to 3 classes.\n",
      "Found 714 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    # rotation_range=2,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # shear_range=0.6,\n",
    "    # zoom_range=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_w, img_h),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(img_w, img_h),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    seed=7,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_w, img_h),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    seed=7,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples\n",
    "train_num = train_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 29s 233ms/step - loss: 0.3984 - accuracy: 0.8413 - val_loss: 0.3625 - val_accuracy: 0.8543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x709a9c337790>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_dir = \"./logs/fit\" + datetime.datetime.now().strftime(\"%d%M%Y-%H%M%S\")\n",
    "tensorboard_callbacks = tf.keras.callbacks.TensorBoard(log_dir=logs_dir)\n",
    "callbacks_list = [tensorboard_callbacks]\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 2s 67ms/step - loss: 0.4708 - accuracy: 0.8053\n",
      "Accuracy obtained: 80.532\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(\n",
    "    test_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Accuracy obtained: {results[1]*100:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(os.path.join(model_dir, \"Mynet1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
